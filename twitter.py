# -*- coding: utf-8 -*-
"""Twitter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t8DcR-awCqn6LMsjnzqFOWUfdrTh15Iu

# Twitter API
"""

# !pip install twython

import os
import tweepy as tw
from twython import Twython
import pandas as pd
import datetime
import re

consumer_key = 'AdW0DwnyMprbY8jPCQBT6wOi0'
consumer_secret = 'z9Uq6O8uW60CN70phXrsWHDGgU4zx5Ex1tfKtSfiaGPItXcbp4'
access_token = '1394308063595614217-tjHbbYsIvoKzdWgljbjnziaMwjxq1l'
access_token_secret = '4FNiCSu2dgRMpW8P0iR94vGS2EhsxhYfNNyW8V4LbgpRU'

auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tw.API(auth)

def get_tweeter_data(profile_name, latest_tweet=False):
  twitter = Twython(consumer_key, consumer_secret, access_token, access_token_secret)

  details = twitter.show_user(screen_name=profile_name)
  extracted = {}
  info = ['favourites_count','name','location','friends_count','followers_count','created_at','statuses_count']
  for data in info:
    extracted[data] = details[data]
  tweets = []
  tweeted_at = []


  for i in tw.Cursor(api.search, q='from:'+profile_name, tweet_mode='extended').items(10):
    tweets.append(i.full_text)
    tweeted_at.append(i.created_at)
  # extracted['latest_tweet_on'] = tweeted_at[0]
  print(tweeted_at)

  import datetime
  s = details['created_at'][:10] + details['created_at'][25:]
  d = datetime.datetime.strptime(s, '%a %b %d %Y')

  extracted['days_per_tweet'] = round(((datetime.datetime.now() - d).days)/details['statuses_count'])

  if latest_tweet:
    return tweets[0], pd.DataFrame(extracted, index=[1])
  else:
    return pd.DataFrame(extracted, index=[1])

data = get_tweeter_data('OfficialGenAI')
data.to_csv('tweeter_data.csv')
